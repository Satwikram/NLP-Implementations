{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Satwikram/NLP-Implementations/blob/main/Quora%20Insincere%20BERT%20%2B%20Feature%20Engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqSb46yu7V93"
      },
      "source": [
        "### Author: Satwik Ram K"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkrZk7jRWM4M"
      },
      "source": [
        "### Connecting to Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "V_iVbNskWP88",
        "outputId": "fdb76208-6595-4e31-fe7b-532c5b475f8e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5c865bb5-cec8-4fe2-986b-9563bb790c0f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5c865bb5-cec8-4fe2-986b-9563bb790c0f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.upload()\n",
        "\n",
        "\n",
        "! mkdir ~/.kaggle\n",
        "\n",
        "\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPfyT4pcWb2v"
      },
      "source": [
        "### Downloading dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oobvh3C7Wa8j"
      },
      "outputs": [],
      "source": [
        "!kaggle competitions download -c quora-insincere-questions-classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4QO4gSIWgo6"
      },
      "outputs": [],
      "source": [
        "!unzip /content/train.csv.zip\n",
        "!unzip /content/test.csv.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfeaFx-X687_"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjZ_lxvR7ayj"
      },
      "source": [
        "### Importing Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1pA832K7EZZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from transformers import BertTokenizer, TFAutoModel\n",
        "import os\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, BatchNormalization, Input, Dropout\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "import nltk\n",
        "\n",
        "# nltk.download(\"stopwords\")\n",
        "# nltk.download(\"wordnet\")\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJv7Gm5zWsvH"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"/content/train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8cnBwoakWzyM",
        "outputId": "c4d12f6e-beca-4b65-99c9-860b1aebed76"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00002165364db923c7e6</td>\n",
              "      <td>How did Quebec nationalists see their province...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000032939017120e6e44</td>\n",
              "      <td>Do you have an adopted dog, how would you enco...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000412ca6e4628ce2cf</td>\n",
              "      <td>Why does velocity affect time? Does velocity a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000042bf85aa498cd78e</td>\n",
              "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0000455dfa3e01eae3af</td>\n",
              "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    qid  ... target\n",
              "0  00002165364db923c7e6  ...      0\n",
              "1  000032939017120e6e44  ...      0\n",
              "2  0000412ca6e4628ce2cf  ...      0\n",
              "3  000042bf85aa498cd78e  ...      0\n",
              "4  0000455dfa3e01eae3af  ...      0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nh2TNWaW8zo"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.drop_duplicates(subset=['qid'], keep='first')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "b4zuyrwlXBfo",
        "outputId": "b42293dc-13d5-4f3d-b66e-789f63d6423a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5fa5b606d0>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEACAYAAACj0I2EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANHklEQVR4nO3df6zdd13H8eeLlmLiEBN6Mdj2che5EytDwZtBxMiUGbuRtH+oZA3+ImX3H0s0ILFGM8z4BzTRxKQTG10mJGwWYsiNK9QER2YYnb0LMNc2nTfdoLeatGzdDCG6Vd/+cc70cHvvPaftt/fcfvp8JDc93+/303PeaW6e+fZ7fqWqkCRd+14x7gEkSd0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUiLEGPcl9Sc4meXLE9e9NcjzJsSSfudrzSdK1JON8HXqSnwW+A3yqqt48ZO00cBD4+ao6n+R1VXV2LeaUpGvBWM/Qq+oR4LnBfUl+JMkXkzye5J+SvKl/6C5gf1Wd7/9dYy5JA9bjNfQDwAer6qeA3wXu7e+/CbgpyVeSHEmyY2wTStI6tHHcAwxKcgPw08Bnk7y8+1X9PzcC08CtwFbgkSQ3V9Xzaz2nJK1H6yro9P7H8HxV/eQyxxaBx6rqJeDpJE/RC/zRtRxQktardXXJpar+g16sfwUgPT/RP/x5emfnJNlM7xLMqXHMKUnr0bhftvgA8FXgR5MsJtkDvA/Yk+QbwDFgV3/5YeDZJMeBh4GPVNWz45hbktajsb5sUZLUnXV1yUWSdPkMuiQ1Ymyvctm8eXNNTU2N6+El6Zr0+OOPf7uqJpY7NragT01NMT8/P66Hl6RrUpJvrnTMSy6S1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNWG+fh77uTO17aNwjNOWZj79n3CNIzRp6hp7kviRnkzy5wvH3JXkiyb8keXTg88slSWtolEsu9wOrfX/n08C7qupm4GP0vhNUkrTGhl5yqapHkkytcvzRgc0j9L7vU5K0xrp+UnQP8IWO71OSNILOnhRN8nP0gv4zq6yZBWYBJicnu3poSRIdnaEneQvwV8Cu1b7ns6oOVNVMVc1MTCz7cb6SpMt0xUFPMgn8HfBrVfXUlY8kSbocQy+5JHkAuBXYnGQR+CjwSoCq+iRwN/Ba4N4kABeqauZqDSxJWt4or3LZPeT4B4APdDaRJOmy+NZ/SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWrE0KAnuS/J2SRPrnA8Sf48yUKSJ5K8rfsxJUnDjHKGfj+wY5XjtwPT/Z9Z4C+ufCxJ0qUaGvSqegR4bpUlu4BPVc8R4AeTvL6rASVJo+niGvoW4PTA9mJ/30WSzCaZTzJ/7ty5Dh5akvSyNX1StKoOVNVMVc1MTEys5UNLUvO6CPoZYNvA9tb+PknSGuoi6HPAr/df7fIO4IWq+vcO7leSdAk2DluQ5AHgVmBzkkXgo8ArAarqk8Ah4A5gAfgu8P6rNawkaWVDg15Vu4ccL+C3OptIknRZfKeoJDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSI0YKepIdSU4mWUiyb5njk0keTvK1JE8kuaP7USVJqxka9CQbgP3A7cB2YHeS7UuW/SFwsKreCtwJ3Nv1oJKk1Y1yhn4LsFBVp6rqReBBYNeSNQX8QP/2a4B/625ESdIoNo6wZgtwemB7EXj7kjV/BPxDkg8C3w/c1sl0kqSRdfWk6G7g/qraCtwBfDrJRfedZDbJfJL5c+fOdfTQkiQYLehngG0D21v7+wbtAQ4CVNVXge8DNi+9o6o6UFUzVTUzMTFxeRNLkpY1StCPAtNJbkyyid6TnnNL1nwLeDdAkh+jF3RPwSVpDQ0NelVdAPYCh4ET9F7NcizJPUl29pd9GLgryTeAB4DfrKq6WkNLki42ypOiVNUh4NCSfXcP3D4OvLPb0SRJl8J3ikpSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSI0YKepIdSU4mWUiyb4U1701yPMmxJJ/pdkxJ0jAbhy1IsgHYD/wCsAgcTTJXVccH1kwDvw+8s6rOJ3nd1RpYkrS8Uc7QbwEWqupUVb0IPAjsWrLmLmB/VZ0HqKqz3Y4pSRpmlKBvAU4PbC/29w26CbgpyVeSHEmyo6sBJUmjGXrJ5RLuZxq4FdgKPJLk5qp6fnBRkllgFmBycrKjh5YkwWhn6GeAbQPbW/v7Bi0Cc1X1UlU9DTxFL/Dfo6oOVNVMVc1MTExc7sySpGWMEvSjwHSSG5NsAu4E5pas+Ty9s3OSbKZ3CeZUh3NKkoYYGvSqugDsBQ4DJ4CDVXUsyT1JdvaXHQaeTXIceBj4SFU9e7WGliRdbKRr6FV1CDi0ZN/dA7cL+FD/R5I0Br5TVJIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaMVLQk+xIcjLJQpJ9q6z7pSSVZKa7ESVJoxga9CQbgP3A7cB2YHeS7cusezXw28BjXQ8pSRpulDP0W4CFqjpVVS8CDwK7lln3MeATwH92OJ8kaUSjBH0LcHpge7G/7/8keRuwraoe6nA2SdIluOInRZO8AvhT4MMjrJ1NMp9k/ty5c1f60JKkAaME/QywbWB7a3/fy14NvBn4cpJngHcAc8s9MVpVB6pqpqpmJiYmLn9qSdJFRgn6UWA6yY1JNgF3AnMvH6yqF6pqc1VNVdUUcATYWVXzV2ViSdKyhga9qi4Ae4HDwAngYFUdS3JPkp1Xe0BJ0mg2jrKoqg4Bh5bsu3uFtbde+ViSpEvlO0UlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREjBT3JjiQnkywk2bfM8Q8lOZ7kiSRfSvKG7keVJK1maNCTbAD2A7cD24HdSbYvWfY1YKaq3gJ8DvjjrgeVJK1ulDP0W4CFqjpVVS8CDwK7BhdU1cNV9d3+5hFga7djSpKGGSXoW4DTA9uL/X0r2QN84UqGkiRduo1d3lmSXwVmgHetcHwWmAWYnJzs8qEl6bo3yhn6GWDbwPbW/r7vkeQ24A+AnVX1X8vdUVUdqKqZqpqZmJi4nHklSSsYJehHgekkNybZBNwJzA0uSPJW4C/pxfxs92NKkoYZGvSqugDsBQ4DJ4CDVXUsyT1JdvaX/QlwA/DZJF9PMrfC3UmSrpKRrqFX1SHg0JJ9dw/cvq3juSRJl8h3ikpSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIzr9TlFJa2dq30PjHqEpz3z8PeMe4Yp5hi5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjRgp6El2JDmZZCHJvmWOvyrJ3/aPP5ZkqutBJUmrGxr0JBuA/cDtwHZgd5LtS5btAc5X1RuBPwM+0fWgkqTVjXKGfguwUFWnqupF4EFg15I1u4C/6d/+HPDuJOluTEnSMKN8ONcW4PTA9iLw9pXWVNWFJC8ArwW+PbgoySww29/8TpKTlzO0lrWZJf/e61H8v9v1yN/Nbr1hpQNr+mmLVXUAOLCWj3m9SDJfVTPjnkNayt/NtTPKJZczwLaB7a39fcuuSbIReA3wbBcDSpJGM0rQjwLTSW5Msgm4E5hbsmYO+I3+7V8G/rGqqrsxJUnDDL3k0r8mvhc4DGwA7quqY0nuAearag74a+DTSRaA5+hFX2vLS1lar/zdXCPxRFqS2uA7RSWpEQZdkhph0CWpEWv6OnR1J8mb6L1Dd0t/1xlgrqpOjG8qSePkGfo1KMnv0fsIhgD/3P8J8MByH54mrQdJ3j/uGVrnq1yuQUmeAn68ql5asn8TcKyqpsczmbSyJN+qqslxz9EyL7lcm/4H+GHgm0v2v75/TBqLJE+sdAj4obWc5Xpk0K9NvwN8Kcm/8v8fnDYJvBHYO7appF60fxE4v2R/gEfXfpzri0G/BlXVF5PcRO+jjQefFD1aVf89vskk/h64oaq+vvRAki+v/TjXF6+hS1IjfJWLJDXCoEtSIwy6JDXCoEtSIwy6JDXifwFVu+f/vHG39AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset[\"target\"].value_counts().plot(kind = \"bar\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJkRrkYDmLmR",
        "outputId": "fac33888-6c24-457e-b6f6-1c00fd9537ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    1225312\n",
              "1      80810\n",
              "Name: target, dtype: int64"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[\"target\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nle6APmmY3h",
        "outputId": "532907ad-9967-4acd-e500-6d2406f5b6c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    20000\n",
              "0    20000\n",
              "Name: target, dtype: int64"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_0 = dataset[dataset[\"target\"]==0].sample(n=20000, replace=False)\n",
        "class_1 = dataset[dataset[\"target\"]==1].sample(n=20000, replace=False)\n",
        "\n",
        "df = pd.concat([class_0, class_1])\n",
        "\n",
        "df[\"target\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88CPMXjBowxM"
      },
      "source": [
        "### Clean Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCNftdOnorCD"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "\n",
        "  lem = nltk.stem.wordnet.WordNetLemmatizer()  # Lemmatization\n",
        "\n",
        "  text = \" \".join(map(lambda x: lem.lemmatize(x), text.split()))\n",
        "\n",
        "  text = re.sub(\"\\s+\", \" \", text)  # Remove extra spaces\n",
        "\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72ptPc2YpvCy"
      },
      "outputs": [],
      "source": [
        "df[\"question_text\"] = df[\"question_text\"].apply(clean_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sj-Cu_Ghp8R_"
      },
      "source": [
        "### Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAR3gg40qDRw"
      },
      "outputs": [],
      "source": [
        "def add_features(df, column):\n",
        "\n",
        "  def count_punct(text):\n",
        "\n",
        "    count = sum([1 for char in text if char in string.punctuation])\n",
        "    return round(count / (len(text) - text.count(\" \")), 3) * 100\n",
        "\n",
        "  def count_stopwords(text):\n",
        "\n",
        "    count = sum([1 for word in text.split() if word in stopwords.words(\"english\")])\n",
        "    return round(count / len(text.split()), 3) * 100\n",
        "\n",
        "  def average_length(text):\n",
        "\n",
        "    word = text.split()\n",
        "    len_char = [len(c) for c in word]\n",
        "    average = sum(len_char) / len(word)\n",
        "    return average\n",
        "\n",
        "  def count_vowels(text):\n",
        "\n",
        "    count = sum([1 for char in text if char in [\"a\", \"e\", \"i\", \"o\", \"u\"]])\n",
        "    return round(count / (len(text) - text.count(\" \")), 3) * 100\n",
        "\n",
        "  def count_articles(text):\n",
        "\n",
        "    count = sum([1 for word in text.split() if word in [\"a\", \"the\", \"an\"]])\n",
        "    return round(count / (len(text.split())), 3) * 100\n",
        "\n",
        "  df[\"length\"] = df[column].apply(lambda x: len(x) - x.count(\" \"))\n",
        "  df[\"Number of words\"] = df[column].apply(lambda x: len(x.split()))\n",
        "  df[\"punct%\"] = df[column].apply(lambda x: count_punct(x))\n",
        "  df[\"stopwords%\"] = df[column].apply(lambda x: count_stopwords(x))\n",
        "  df[\"Average length of words\"] = df[column].apply(lambda x: average_length(x))\n",
        "  df[\"vowel%\"] = df[column].apply(lambda x: count_vowels(x))\n",
        "  df[\"article%\"] = df[column].apply(lambda x: count_articles(x))\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdH41XOGtUjK"
      },
      "outputs": [],
      "source": [
        "df = add_features(df, \"question_text\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "VsD-BJcWvCbp",
        "outputId": "e43a9624-c779-4474-81e9-be1364e72957"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "      <th>target</th>\n",
              "      <th>length</th>\n",
              "      <th>Number of words</th>\n",
              "      <th>punct%</th>\n",
              "      <th>stopwords%</th>\n",
              "      <th>Average length of words</th>\n",
              "      <th>vowel%</th>\n",
              "      <th>article%</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>99597</th>\n",
              "      <td>1380c98defe62e563121</td>\n",
              "      <td>How often do blackbird lay eggs?</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>6</td>\n",
              "      <td>3.7</td>\n",
              "      <td>16.7</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>29.6</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>317702</th>\n",
              "      <td>3e439b3cfceb568c3946</td>\n",
              "      <td>What were Jiddu Krishnamurti's literary influe...</td>\n",
              "      <td>0</td>\n",
              "      <td>46</td>\n",
              "      <td>6</td>\n",
              "      <td>4.3</td>\n",
              "      <td>16.7</td>\n",
              "      <td>7.666667</td>\n",
              "      <td>34.8</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>715948</th>\n",
              "      <td>8c26cd4baa8400425913</td>\n",
              "      <td>I own two Instagram accounts. Is there any way...</td>\n",
              "      <td>0</td>\n",
              "      <td>78</td>\n",
              "      <td>19</td>\n",
              "      <td>2.6</td>\n",
              "      <td>47.4</td>\n",
              "      <td>4.105263</td>\n",
              "      <td>34.6</td>\n",
              "      <td>10.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>651650</th>\n",
              "      <td>7fa35316e8557092e11f</td>\n",
              "      <td>What is life like in a Texas police academy?</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>9</td>\n",
              "      <td>2.8</td>\n",
              "      <td>33.3</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>44.4</td>\n",
              "      <td>11.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1201736</th>\n",
              "      <td>eb86101831cd96c291cf</td>\n",
              "      <td>What is an important lesson you can learn by r...</td>\n",
              "      <td>0</td>\n",
              "      <td>70</td>\n",
              "      <td>14</td>\n",
              "      <td>4.3</td>\n",
              "      <td>35.7</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>37.1</td>\n",
              "      <td>7.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          qid  ... article%\n",
              "99597    1380c98defe62e563121  ...      0.0\n",
              "317702   3e439b3cfceb568c3946  ...      0.0\n",
              "715948   8c26cd4baa8400425913  ...     10.5\n",
              "651650   7fa35316e8557092e11f  ...     11.1\n",
              "1201736  eb86101831cd96c291cf  ...      7.1\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "U4IWKbRjvKFC",
        "outputId": "dfba664e-39c2-48e9-896e-28dac11a2d6c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>length</th>\n",
              "      <th>Number of words</th>\n",
              "      <th>punct%</th>\n",
              "      <th>stopwords%</th>\n",
              "      <th>Average length of words</th>\n",
              "      <th>vowel%</th>\n",
              "      <th>article%</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>40000.000000</td>\n",
              "      <td>40000.000000</td>\n",
              "      <td>40000.000000</td>\n",
              "      <td>40000.00000</td>\n",
              "      <td>40000.000000</td>\n",
              "      <td>40000.000000</td>\n",
              "      <td>40000.000000</td>\n",
              "      <td>40000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>68.461575</td>\n",
              "      <td>14.842900</td>\n",
              "      <td>3.14875</td>\n",
              "      <td>35.506153</td>\n",
              "      <td>4.657078</td>\n",
              "      <td>35.823068</td>\n",
              "      <td>6.283458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.500006</td>\n",
              "      <td>40.252286</td>\n",
              "      <td>8.618662</td>\n",
              "      <td>1.98207</td>\n",
              "      <td>11.851916</td>\n",
              "      <td>0.784889</td>\n",
              "      <td>4.213654</td>\n",
              "      <td>6.588928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>2.00000</td>\n",
              "      <td>28.600000</td>\n",
              "      <td>4.137931</td>\n",
              "      <td>33.300000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>2.70000</td>\n",
              "      <td>36.800000</td>\n",
              "      <td>4.600000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>5.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>3.80000</td>\n",
              "      <td>43.800000</td>\n",
              "      <td>5.100000</td>\n",
              "      <td>38.500000</td>\n",
              "      <td>11.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>292.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>47.40000</td>\n",
              "      <td>72.700000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>57.100000</td>\n",
              "      <td>44.400000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             target        length  ...        vowel%      article%\n",
              "count  40000.000000  40000.000000  ...  40000.000000  40000.000000\n",
              "mean       0.500000     68.461575  ...     35.823068      6.283458\n",
              "std        0.500006     40.252286  ...      4.213654      6.588928\n",
              "min        0.000000      1.000000  ...      0.000000      0.000000\n",
              "25%        0.000000     39.000000  ...     33.300000      0.000000\n",
              "50%        0.500000     56.000000  ...     36.000000      5.600000\n",
              "75%        1.000000     87.000000  ...     38.500000     11.100000\n",
              "max        1.000000    292.000000  ...     57.100000     44.400000\n",
              "\n",
              "[8 rows x 8 columns]"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZepyjYYz2hrJ"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siBdoN_B2kXO"
      },
      "outputs": [],
      "source": [
        "pretrained_model = \"bert-base-uncased\"\n",
        "sequence_length = 128\n",
        "batch_size = 64\n",
        "epochs=30\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(pretrained_model)\n",
        "\n",
        "tokens = tokenizer(\n",
        "    df[\"question_text\"].tolist(),\n",
        "    max_length=sequence_length,\n",
        "    truncation=True,\n",
        "    padding=\"max_length\",\n",
        "    add_special_tokens=True,\n",
        "    return_tensors=\"np\"\n",
        ")\n",
        "\n",
        "df[\"Xids\"] = tokens[\"input_ids\"].tolist()\n",
        "df[\"Xmasks\"] = tokens[\"attention_mask\"].tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IyZWLN1Xg8Z"
      },
      "source": [
        "### Preparing inputs and outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U277lUSDXENy"
      },
      "outputs": [],
      "source": [
        "X = df.drop(columns=[\"question_text\", \"qid\", \"target\"])\n",
        "y = df[\"target\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_c4tYqN5xSs"
      },
      "source": [
        "### Train Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRw1sH-aXnaR"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzqJkAVy8OUO"
      },
      "outputs": [],
      "source": [
        "X_train_ids = np.vstack(X_train[\"Xids\"])\n",
        "X_train_mask = np.vstack(X_train[\"Xmasks\"])\n",
        "X_train_inputs = X_train.drop(columns=[\"Xids\", \"Xmasks\"]).values\n",
        "\n",
        "X_test_ids = np.vstack(X_test[\"Xids\"])\n",
        "X_test_mask = np.vstack(X_test[\"Xmasks\"])\n",
        "X_test_inputs = X_test.drop(columns=[\"Xids\", \"Xmasks\"]).values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doyRBZqHY3HM"
      },
      "source": [
        "### Building BERT Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ui9ciWNcVR05",
        "outputId": "64a8fdf1-338f-4722-d13b-d8c653e98357"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "bert = TFAutoModel.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ko8Wp51UhBc",
        "outputId": "3cd7c504-2a00-439d-fd32-b1bc7d616c8e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 7) dtype=int32 (created by layer 'inputs')>"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afuoiYaX8PFx"
      },
      "outputs": [],
      "source": [
        "input_ids = tf.keras.layers.Input(shape = (sequence_length,), name = \"input_ids\",\n",
        "                                  dtype = \"int32\")\n",
        "\n",
        "mask = tf.keras.layers.Input(shape = (sequence_length,), name = \"attention_mask\",\n",
        "                                  dtype = \"int32\")\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape = X_train_inputs[0].shape, name = \"inputs\",\n",
        "                                  dtype = \"int32\")\n",
        "\n",
        "embeddings = bert(input_ids, attention_mask = mask)[0]\n",
        "                                    \n",
        "x1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences = True))(embeddings)\n",
        "x1 = tf.keras.layers.BatchNormalization()(x1)\n",
        "x1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128))(x1)\n",
        "x1 = tf.keras.layers.Dense(64, activation=\"relu\")(x1)\n",
        "\n",
        "x2 = tf.keras.layers.Dense(256, activation=\"relu\")(inputs)\n",
        "x2 = tf.keras.layers.BatchNormalization()(x2)\n",
        "x2 = tf.keras.layers.Dense(128, activation=\"relu\")(x2)\n",
        "x2 = tf.keras.layers.Dense(64, activation=\"relu\")(x2)\n",
        "\n",
        "x = tf.concat([x1, x2], axis=-1)\n",
        "x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "x = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n",
        "\n",
        "y = tf.keras.layers.Dense(1, activation = \"sigmoid\", name = \"outputs\")(x)\n",
        "\n",
        "model = tf.keras.Model(inputs = [input_ids, mask, inputs], outputs = y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1plJ-XqbNe1"
      },
      "outputs": [],
      "source": [
        "model.layers[2].trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTCB4RvtbTh1",
        "outputId": "f3089bfd-f849-4b1b-f5bc-1a2e9b65dc2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model_3 (TFBertModel)  TFBaseModelOutputWi  109482240   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 128,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " inputs (InputLayer)            [(None, 7)]          0           []                               \n",
            "                                                                                                  \n",
            " bidirectional_27 (Bidirectiona  (None, 128, 512)    2099200     ['tf_bert_model_3[0][0]']        \n",
            " l)                                                                                               \n",
            "                                                                                                  \n",
            " dense_30 (Dense)               (None, 256)          2048        ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 128, 512)    2048        ['bidirectional_27[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 256)         1024        ['dense_30[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " bidirectional_28 (Bidirectiona  (None, 256)         656384      ['batch_normalization_22[0][0]'] \n",
            " l)                                                                                               \n",
            "                                                                                                  \n",
            " dense_31 (Dense)               (None, 128)          32896       ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " dense_29 (Dense)               (None, 64)           16448       ['bidirectional_28[0][0]']       \n",
            "                                                                                                  \n",
            " dense_32 (Dense)               (None, 64)           8256        ['dense_31[0][0]']               \n",
            "                                                                                                  \n",
            " tf.concat_4 (TFOpLambda)       (None, 128)          0           ['dense_29[0][0]',               \n",
            "                                                                  'dense_32[0][0]']               \n",
            "                                                                                                  \n",
            " dense_33 (Dense)               (None, 128)          16512       ['tf.concat_4[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_151 (Dropout)          (None, 128)          0           ['dense_33[0][0]']               \n",
            "                                                                                                  \n",
            " dense_34 (Dense)               (None, 64)           8256        ['dropout_151[0][0]']            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 1)            65          ['dense_34[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 112,325,377\n",
            "Trainable params: 2,841,601\n",
            "Non-trainable params: 109,483,776\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIdm33qwisn2",
        "outputId": "387615b0-12bc-4510-a943-77f04d94458d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(lr = 5e-5, decay = 1e-6)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDvqYew7jDQV"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = optimizer, loss = loss, metrics = [acc])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBOq8QTDjI5M"
      },
      "source": [
        "### Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhgzITdqjGKd"
      },
      "outputs": [],
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"models\", monitor = \"val_loss\", save_best_only = True, \n",
        "                                                verbose = 1)\n",
        "\n",
        "earlystopping = tf.keras.callbacks.EarlyStopping( monitor = \"val_loss\", verbose = 1, restore_best_weights = True,\n",
        "                                                 patience = 2)\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.2,\n",
        "                              patience = 1, min_lr = 0.001, verbose = 1)\n",
        "\n",
        "callbacks = [checkpoint, earlystopping, reduce_lr]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxdQbcudjLQM",
        "outputId": "505d5aa4-e61f-434e-8cd4-abc6c4cebe4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 00001: val_loss improved from inf to 0.00000, saving model to models\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 1075). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f5ee9075590> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f5ee22bd910> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f5ee33f35d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f5ee22d77d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1000/1000 [==============================] - 944s 929ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 5.0000e-05\n"
          ]
        }
      ],
      "source": [
        "history = model.fit([X_train_ids, X_train_mask, X_train_inputs], y_train, validation_data = ([X_test_ids, X_test_mask, X_test_inputs], y_test), epochs = 1, callbacks = callbacks)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Quora Insincere - BERT + Feature Engineering.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOdqAd6kiOVCMY2CdPMTo7C",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}