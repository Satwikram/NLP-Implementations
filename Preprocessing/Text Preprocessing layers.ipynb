{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Preprocessing layers.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMd8glAAgIhlfEwB1rj3bRw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Satwikram/NLP-Implementations/blob/main/Preprocessing/Text%20Preprocessing%20layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Author: Satwik Ram K\n",
        "\n",
        "Working with preprocessing layers"
      ],
      "metadata": {
        "id": "dXdKxRv0tuYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "QeQ3ir2buAkA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vx3mCqBTtTDT"
      },
      "outputs": [],
      "source": [
        "data = [\"How\", \"are\", \"you ...\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the text processing layer"
      ],
      "metadata": {
        "id": "WEMmSiGJu7QU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer = layers.TextVectorization()\n",
        "layer.adapt(data)\n",
        "vectorized_text = layer(data)\n",
        "print(vectorized_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZeYuJx2ubZi",
        "outputId": "8f1644f9-e5a3-487b-ab11-96345b68d1ae"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[3]\n",
            " [4]\n",
            " [2]], shape=(3, 1), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the vocab"
      ],
      "metadata": {
        "id": "PbWjp3c_u_jm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = [\"a\", \"b\", \"c\", \"d\"]\n",
        "data = tf.constant([[\"a\", \"c\", \"d\"], [\"d\", \"z\", \"b\"]])\n",
        "layer = layers.StringLookup(vocabulary=vocab)\n",
        "vectorized_data = layer(data)\n",
        "print(vectorized_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DdYnJBcueW0",
        "outputId": "ab23b7f4-6759-4ac6-c026-3a38efcb9d1a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1 3 4]\n",
            " [4 0 2]], shape=(2, 3), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the layers before training the model"
      ],
      "metadata": {
        "id": "Vao5bA2Qv6et"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adapt_data = tf.constant(\n",
        "    [\n",
        "        \"The Brain is wider than the Sky\",\n",
        "        \"For put them side by side\",\n",
        "        \"The one the other will contain\",\n",
        "        \"With ease and You beside\",\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Create a TextVectorization layer\n",
        "text_vectorizer = layers.TextVectorization(output_mode=\"int\")\n",
        "text_vectorizer.adapt(adapt_data)\n",
        "\n",
        "\n",
        "# Try out the layer\n",
        "print(\n",
        "    \"Encoded text:\\n\", text_vectorizer([\"The Brain is deeper than the sea\"]).numpy(),\n",
        ")\n",
        "\n",
        "# Create a simple model\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "x = layers.Embedding(input_dim=text_vectorizer.vocabulary_size(), output_dim=16)(inputs)\n",
        "x = layers.GRU(8)(x)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "# Create a labeled dataset (which includes unknown tokens)\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    ([\"The Brain is deeper than the sea\", \"for if they are held Blue to Blue\"], [1, 0])\n",
        ")\n",
        "\n",
        "# Preprocess the string inputs, turning them into int sequences\n",
        "train_dataset = train_dataset.batch(2).map(lambda x, y: (text_vectorizer(x), y))\n",
        "print(train_dataset)\n",
        "# Train the model on the int sequences\n",
        "print(\"\\nTraining model...\")\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"mse\")\n",
        "model.fit(train_dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQFRej6tvWEU",
        "outputId": "d506f6d1-cc8e-4e96-93f9-9327adc7bb33"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7f784dd36200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Encoded text:\n",
            " [[ 2 19 14  1  9  2  1]]\n",
            "<MapDataset shapes: ((None, None), (None,)), types: (tf.int64, tf.int32)>\n",
            "\n",
            "Training model...\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4866\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f784dd9d4d0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the layer inside the model"
      ],
      "metadata": {
        "id": "YtTaBWfY097E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For inference, you can export a model that accepts strings as input\n",
        "inputs = keras.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "outputs = model(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "# Call the end-to-end model on test data (which includes unknown tokens)\n",
        "print(\"\\nCalling end-to-end model on test string...\")\n",
        "test_data = tf.constant([\"The one the other will absorb\"])\n",
        "test_output = model(test_data)\n",
        "print(\"Model output:\", test_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jP7qVbawzSHE",
        "outputId": "0801244c-0b6e-4a2a-d153-13d93bfee4b8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Calling end-to-end model on test string...\n",
            "Model output: tf.Tensor([[0.0418027]], shape=(1, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aYGy4G_vztXc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}