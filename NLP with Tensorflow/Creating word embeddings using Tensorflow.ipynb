{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Satwikram/NLP-Implementations/blob/main/NLP%20with%20Tensorflow/Creating%20word%20embeddings%20using%20Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZUQErGewZxE"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RutaI-Tpev3T"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "from tensorboard.plugins import projector\n",
        "\n",
        "os.makedirs(\"logs\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Dataset"
      ],
      "metadata": {
        "id": "QANVDbp5jvXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_excel(\"/content/testing_vocab.xlsx\")"
      ],
      "metadata": {
        "id": "JYaU-LAUYO9G"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"target\"] = dataset[\"DO Type\"].apply(lambda x: 0 if x==\"Deliverable\" else 1)"
      ],
      "metadata": {
        "id": "MqyDSATOYakn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGicgV5qT0wh"
      },
      "source": [
        "## Text preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2MlsXzo-ZlfK"
      },
      "outputs": [],
      "source": [
        "def custom_standardization(input_data):\n",
        "  lowercase = tf.strings.lower(input_data)\n",
        "  return tf.strings.regex_replace(lowercase,\n",
        "                                  '[%s]' % re.escape(string.punctuation), '')\n",
        "\n",
        "\n",
        "vocab_size = 600\n",
        "sequence_length = 100\n",
        "\n",
        "\n",
        "vectorize_layer = TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=sequence_length)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n",
        "X = dataset[\"Relevant Description\"].values\n",
        "y = dataset[\"target\"].values\n",
        "\n",
        "vectorize_layer.adapt(X)"
      ],
      "metadata": {
        "id": "Y7z4gjD6ZWRA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Building"
      ],
      "metadata": {
        "id": "0GLkhzRskCsA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pHLcFtn5Wsqj"
      },
      "outputs": [],
      "source": [
        "embedding_dim=16\n",
        "\n",
        "model = Sequential([\n",
        "  vectorize_layer,\n",
        "  Embedding(vocab_size, embedding_dim, name=\"embedding\"),\n",
        "  GlobalAveragePooling1D(),\n",
        "  Dense(16, activation='relu'),\n",
        "  Dense(1)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjLNgKO7W2fe"
      },
      "source": [
        "## Compile and train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "W4Hg3IHFt4Px"
      },
      "outputs": [],
      "source": [
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OrKAKAKIbuH"
      },
      "source": [
        "Compile and train the model using the `Adam` optimizer and `BinaryCrossentropy` loss. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lCUgdP69Wzix"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5mQehiQyv8rP",
        "outputId": "ee163f60-ffb5-4210-9721-55f2777b49f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "3/3 [==============================] - 1s 10ms/step - loss: 0.6883 - accuracy: 0.6716\n",
            "Epoch 2/15\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6857 - accuracy: 0.6716\n",
            "Epoch 3/15\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6822 - accuracy: 0.6716\n",
            "Epoch 4/15\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.6795 - accuracy: 0.6716\n",
            "Epoch 5/15\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.6766 - accuracy: 0.6716\n",
            "Epoch 6/15\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.6739 - accuracy: 0.6716\n",
            "Epoch 7/15\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.6711 - accuracy: 0.6716\n",
            "Epoch 8/15\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.6685 - accuracy: 0.6716\n",
            "Epoch 9/15\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.6659 - accuracy: 0.6716\n",
            "Epoch 10/15\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.6634 - accuracy: 0.6716\n",
            "Epoch 11/15\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.6607 - accuracy: 0.6716\n",
            "Epoch 12/15\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.6582 - accuracy: 0.6716\n",
            "Epoch 13/15\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.6557 - accuracy: 0.6716\n",
            "Epoch 14/15\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.6532 - accuracy: 0.6716\n",
            "Epoch 15/15\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.6505 - accuracy: 0.6716\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f540f383ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "model.fit(X, y, epochs=15,callbacks=[tensorboard_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_Uamp1YH8RzU"
      },
      "outputs": [],
      "source": [
        "weights =  tf.Variable(model.get_layer('embedding').get_weights()[0])\n",
        "vocab = vectorize_layer.get_vocabulary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "log_dir = Path(\"logs/projector\")\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(embedding=weights)\n",
        "checkpoint.save(log_dir/\"embedding.ckpt\")\n",
        "\n",
        "with open(log_dir/\"metadata.tsv\", \"w\") as f:\n",
        "  for word in vocab:\n",
        "    f.write(\"{}\\n\".format(word))\n",
        "\n",
        "config = projector.ProjectorConfig()\n",
        "embedding = config.embeddings.add()\n",
        "# The name of the tensor will be suffixed by `/.ATTRIBUTES/VARIABLE_VALUE`.\n",
        "embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
        "embedding.metadata_path = 'metadata.tsv'\n",
        "projector.visualize_embeddings(log_dir, config)"
      ],
      "metadata": {
        "id": "kENCcXREg8Tr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#docs_infra: no_execute\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/logs/projector"
      ],
      "metadata": {
        "id": "39P1ubhBimpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bl8DmV0ImKTR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Creating word embeddings using Tensorflow.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}