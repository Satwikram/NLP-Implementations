{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author: Satwik Ram K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(r\"/mnt/ml-fileshare/GitHub/dewatson/data/input/consolidated_data_20211012.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_excel(path, engine = \"openpyxl\", usecols = [\"Clean Description\", \"DO Type\", \"Priority\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DO Type', 'Priority', 'Clean Description'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DO Type</th>\n",
       "      <th>Priority</th>\n",
       "      <th>Clean Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Obligation</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>In performing the Services, IBM shall follow t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Obligation</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>In performing the Services, IBM shall follow t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Obligation</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>In performing the Services, IBM shall follow t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DO Type  Priority                                  Clean Description\n",
       "0  Obligation  Moderate  In performing the Services, IBM shall follow t...\n",
       "1  Obligation  Moderate  In performing the Services, IBM shall follow t...\n",
       "2  Obligation  Moderate  In performing the Services, IBM shall follow t..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up the Priority labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def priority(x):\n",
    "\n",
    "    if x in [\"3 - Moderate\", \"moderate\"]:\n",
    "        return \"Moderate\"\n",
    "\n",
    "    elif x in [\"2 - High\", \"2-High\", \"high\"]:\n",
    "        return \"High\"\n",
    "    \n",
    "    elif x in [\"4 - Low\", \"low\"]:\n",
    "        return \"Low\"\n",
    "\n",
    "    elif x in [\"1 - Critical\", \"critical\"]:\n",
    "        return \"Critical\"\n",
    "\n",
    "    else: return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Priority\"] =  dataset[\"Priority\"].apply(lambda x: priority(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Moderate', 'High', 'Low', 'Critical', 'TBD', 'All'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"Priority\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking Each Class samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dataset[dataset[\"DO Type\"] == \"Deliverable\"].sample(frac = 0.2, random_state = 5).head(5)\n",
    "o = dataset[dataset[\"DO Type\"] == \"Obligation\"].sample(frac = 0.2, random_state = 5).head(5)\n",
    "n = dataset[dataset[\"DO Type\"] == \"Neither\"].sample(frac = 1, random_state = 5).head(5)\n",
    "cd = dataset[dataset[\"DO Type\"] == \"Critical Deliverable\"].sample(frac = 0.2, random_state = 5).head(5)\n",
    "p1 = dataset[dataset[\"Priority\"] == \"High\"].sample(frac = 0.2, random_state = 5).head(5)\n",
    "p2 = dataset[dataset[\"Priority\"] == \"Moderate\"].sample(frac = 0.2, random_state = 5).head(5)\n",
    "p3 = dataset[dataset[\"Priority\"] == \"Low\"].sample(frac = 0.2, random_state = 5).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([d, o, n, cd, p1, p2, p3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Deliverable', 'Obligation', 'Critical Deliverable'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"DO Type\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking X, Y1, and Y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"Clean Description\"]\n",
    "y1 = data[\"DO Type\"]\n",
    "y2 = data[\"Priority\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "embedding_dim = 16\n",
    "max_length = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token = \"<oov>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tokenizer.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(X, maxlen = max_length, truncating = \"post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le1 = LabelEncoder()\n",
    "le2 = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = le1.fit_transform(y1)\n",
    "y2 = le2.fit_transform(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Critical Deliverable', 'Deliverable', 'Obligation'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le1.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Critical', 'High', 'Low', 'Moderate'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le2.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_do_type(inputs):     \n",
    "    \n",
    "    x = tf.keras.layers.Embedding(10000, 16, input_length = 150)(inputs)\n",
    "\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(512, activation = \"relu\")(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(3, activation = \"softmax\", name = \"do_outputs\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def build_priority(inputs):\n",
    "\n",
    "    x = tf.keras.layers.Embedding(10000, 16, input_length = 150)(inputs)\n",
    "\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(512, activation = \"relu\")(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(4, activation = \"softmax\", name = \"priority_outputs\")(x)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape = (150,), dtype='int32')\n",
    "\n",
    "model1 = build_do_type(inputs)\n",
    "model2 = build_priority(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging two models into single!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(\n",
    "    inputs = inputs,\n",
    "    outputs = [model1, model2],\n",
    "    name = \"multi-output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"multi-output\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 150, 16)      160000      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 150, 16)      160000      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 16)           0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 16)           0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          8704        global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          8704        global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "do_outputs (Dense)              (None, 3)            1539        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "priority_outputs (Dense)        (None, 4)            2052        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 340,999\n",
      "Trainable params: 340,999\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\n",
    "\t\"do_outputs\": \"sparse_categorical_crossentropy\",\n",
    "\t\"priority_outputs\": \"sparse_categorical_crossentropy\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"adam\", loss = losses, metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3, 3, 1, 3, 1, 3, 1, 3, 3, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 3, 3,\n",
       "        3, 3, 3, 2, 2, 2, 2, 2]),\n",
       " array([1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 2, 2, 2, 1, 2, 2]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2, y1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 1s 944ms/step - loss: 2.4857 - do_outputs_loss: 1.0987 - priority_outputs_loss: 1.3870 - do_outputs_accuracy: 0.4333 - priority_outputs_accuracy: 0.2333\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4767 - do_outputs_loss: 1.0936 - priority_outputs_loss: 1.3831 - do_outputs_accuracy: 0.5000 - priority_outputs_accuracy: 0.4000\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4684 - do_outputs_loss: 1.0888 - priority_outputs_loss: 1.3796 - do_outputs_accuracy: 0.5000 - priority_outputs_accuracy: 0.4667\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4605 - do_outputs_loss: 1.0843 - priority_outputs_loss: 1.3762 - do_outputs_accuracy: 0.5000 - priority_outputs_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4528 - do_outputs_loss: 1.0799 - priority_outputs_loss: 1.3730 - do_outputs_accuracy: 0.5000 - priority_outputs_accuracy: 0.5333\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4451 - do_outputs_loss: 1.0754 - priority_outputs_loss: 1.3697 - do_outputs_accuracy: 0.5000 - priority_outputs_accuracy: 0.5333\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4372 - do_outputs_loss: 1.0708 - priority_outputs_loss: 1.3663 - do_outputs_accuracy: 0.5000 - priority_outputs_accuracy: 0.5333\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4291 - do_outputs_loss: 1.0662 - priority_outputs_loss: 1.3629 - do_outputs_accuracy: 0.5000 - priority_outputs_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4208 - do_outputs_loss: 1.0613 - priority_outputs_loss: 1.3594 - do_outputs_accuracy: 0.5000 - priority_outputs_accuracy: 0.4000\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4122 - do_outputs_loss: 1.0564 - priority_outputs_loss: 1.3558 - do_outputs_accuracy: 0.5000 - priority_outputs_accuracy: 0.3667\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.4034 - do_outputs_loss: 1.0514 - priority_outputs_loss: 1.3521 - do_outputs_accuracy: 0.5000 - priority_outputs_accuracy: 0.3667\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.3944 - do_outputs_loss: 1.0462 - priority_outputs_loss: 1.3482 - do_outputs_accuracy: 0.5000 - priority_outputs_accuracy: 0.3667\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3851 - do_outputs_loss: 1.0408 - priority_outputs_loss: 1.3443 - do_outputs_accuracy: 0.5000 - priority_outputs_accuracy: 0.3667\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3756 - do_outputs_loss: 1.0354 - priority_outputs_loss: 1.3402 - do_outputs_accuracy: 0.5000 - priority_outputs_accuracy: 0.3667\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3660 - do_outputs_loss: 1.0299 - priority_outputs_loss: 1.3360 - do_outputs_accuracy: 0.5000 - priority_outputs_accuracy: 0.3667\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3562 - do_outputs_loss: 1.0244 - priority_outputs_loss: 1.3318 - do_outputs_accuracy: 0.5000 - priority_outputs_accuracy: 0.3667\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3463 - do_outputs_loss: 1.0188 - priority_outputs_loss: 1.3275 - do_outputs_accuracy: 0.5000 - priority_outputs_accuracy: 0.3667\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3364 - do_outputs_loss: 1.0133 - priority_outputs_loss: 1.3231 - do_outputs_accuracy: 0.5000 - priority_outputs_accuracy: 0.3667\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3265 - do_outputs_loss: 1.0078 - priority_outputs_loss: 1.3187 - do_outputs_accuracy: 0.5000 - priority_outputs_accuracy: 0.3667\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3166 - do_outputs_loss: 1.0023 - priority_outputs_loss: 1.3143 - do_outputs_accuracy: 0.5000 - priority_outputs_accuracy: 0.3667\n"
     ]
    }
   ],
   "source": [
    "history =  model.fit(x = X, y = {\"do_outputs\": y1, \"priority_outputs\": y2}, epochs = 20, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_output = y_pred[0]\n",
    "priority_output = y_pred[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_output = np.argmax(do_output, axis = -1)\n",
    "priority_output = np.argmax(priority_output, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " array([1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 2, 2, 2, 1, 2, 2]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_output, y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3]),\n",
       " array([3, 3, 1, 3, 1, 3, 1, 3, 3, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 3, 3,\n",
       "        3, 3, 3, 2, 2, 2, 2, 2]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priority_output, y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.50      1.00      0.67        15\n",
      "           2       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.50        30\n",
      "   macro avg       0.17      0.33      0.22        30\n",
      "weighted avg       0.25      0.50      0.33        30\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.00      0.00      0.00         9\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.37      1.00      0.54        11\n",
      "\n",
      "    accuracy                           0.37        30\n",
      "   macro avg       0.09      0.25      0.13        30\n",
      "weighted avg       0.13      0.37      0.20        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/MLDev02Admin/.cache/pypoetry/virtualenvs/dewatson-5t89fjxv-py3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/MLDev02Admin/.cache/pypoetry/virtualenvs/dewatson-5t89fjxv-py3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/MLDev02Admin/.cache/pypoetry/virtualenvs/dewatson-5t89fjxv-py3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/MLDev02Admin/.cache/pypoetry/virtualenvs/dewatson-5t89fjxv-py3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/MLDev02Admin/.cache/pypoetry/virtualenvs/dewatson-5t89fjxv-py3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/MLDev02Admin/.cache/pypoetry/virtualenvs/dewatson-5t89fjxv-py3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y1, do_output))\n",
    "\n",
    "print(classification_report(y2, priority_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bb2b0588db843fc3b553182f305f92c6cd355d88d4314c582a9609731f465503"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('dewatson-5t89fjxv-py3.8': poetry)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
